#!/usr/bin/env python3
"""
Turkish StorytellerLLM Service
Optimized for 5-year-old girl with remote OpenAI GPT-4 processing
No local models - everything via API
"""

import os
import sys
import json
import asyncio
import logging
import random
from typing import Dict, List, Optional, Any
from datetime import datetime
from pathlib import Path

# Add the current directory to path for imports
sys.path.append(str(Path(__file__).parent))

try:
    import openai
    from openai import OpenAI
except ImportError:
    openai = None
    OpenAI = None

class TurkishStorytellerLLM:
    """Turkish storyteller LLM service optimized for 5-year-old girl"""
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self.client = None
        self.is_initialized = False
        self.story_history = []
        self.current_session = None
        
        # Turkish storytelling configuration
        self.child_config = {
            'name': os.getenv('CHILD_NAME', 'KÃ¼Ã§Ã¼k Prenses'),
            'age': int(os.getenv('CHILD_AGE', '5')),
            'gender': os.getenv('CHILD_GENDER', 'kÄ±z'),
            'language': os.getenv('STORY_LANGUAGE', 'turkish'),
            'target_audience': os.getenv('STORY_TARGET_AUDIENCE', '5_year_old_girl')
        }
        
        # Story configuration
        self.story_config = {
            'themes': os.getenv('STORY_THEMES', 'prenses,peri,dostluk,macera,hayvanlar').split(','),
            'length': os.getenv('STORY_LENGTH', 'short'),
            'tone': os.getenv('STORY_TONE', 'gentle_enthusiastic'),
            'include_moral': os.getenv('STORY_INCLUDE_MORAL', 'true').lower() == 'true',
            'avoid_scary': os.getenv('STORY_AVOID_SCARY', 'true').lower() == 'true',
            'content_filter': os.getenv('STORY_CONTENT_FILTER', 'very_strict')
        }
        
        # OpenAI configuration
        self.openai_config = {
            'api_key': os.getenv('OPENAI_API_KEY'),
            'model': os.getenv('LLM_MODEL', 'gpt-4'),
            'temperature': float(os.getenv('LLM_TEMPERATURE', '0.8')),
            'max_tokens': int(os.getenv('LLM_MAX_TOKENS', '800')),
            'top_p': float(os.getenv('LLM_TOP_P', '0.9')),
            'frequency_penalty': float(os.getenv('LLM_FREQUENCY_PENALTY', '0.1')),
            'presence_penalty': float(os.getenv('LLM_PRESENCE_PENALTY', '0.1'))
        }
        
        # Turkish system prompts
        self.system_prompts = self._load_turkish_prompts()
        
        self.logger.info(f"Turkish StorytellerLLM initialized for {self.child_config['name']}")
    
    def _load_turkish_prompts(self) -> Dict[str, Any]:
        """Load Turkish storytelling prompts"""
        return {
            'main_system_prompt': '''Sen 5 yaÅŸÄ±ndaki sevimli bir kÄ±z Ã§ocuÄŸu iÃ§in hikaye anlatan Ã¶zel asistansÄ±n. 
            AdÄ±n "Hikaye AsistanÄ±" ve sen her zaman nazik, sevecen ve eÄŸlenceli hikayeleri anlatÄ±rsÄ±n.
            
            KURALLAR:
            1. Hikayelerin hep gÃ¼zel, pozitif ve yaÅŸa uygun olmalÄ±
            2. KorkunÃ§, Ã¼zÃ¼cÃ¼ veya korkutucu ÅŸeyler anlatmamalÄ±sÄ±n
            3. Her hikaye 2-3 dakika sÃ¼rmeli (yaklaÅŸÄ±k 150-200 kelime)
            4. Prenses, peri, dostluk, macera ve hayvan hikayeleri anlatmayÄ± seviyorsun
            5. Her hikayenin sonunda gÃ¼zel bir mesaj olmalÄ±
            6. TÃ¼rkÃ§e konuÅŸmalÄ±sÄ±n ve kelimelerini Ã§ocuÄŸun anlayabileceÄŸi ÅŸekilde seÃ§melisin
            7. CÃ¼mlelerini kÄ±sa ve anlaÅŸÄ±lÄ±r tutmalÄ±sÄ±n
            8. Hikaye bittiÄŸinde "Ve iÅŸte hikayemiz bÃ¶yle bitiyor kÃ¼Ã§Ã¼k prenses!" diyerek bitirmelisin
            
            Ã–RNEK KONULAR:
            - Prenses hikayeleri
            - Peri masallarÄ±  
            - Dostluk hikayeleri
            - Sevimli hayvan hikayeleri
            - Macera hikayeleri
            - DoÄŸa hikayeleri
            
            Her zaman Ã§ocuksu bir coÅŸku ve sevgi ile konuÅŸmalÄ±sÄ±n!''',
            
            'greeting_prompts': [
                "Merhaba kÃ¼Ã§Ã¼k prenses! BugÃ¼n sana ne hikayesi anlatayÄ±m?",
                "Selam sevgili prensesim! Hangi hikayeyi duymak istersin?",
                "Merhaba tatlÄ±m! BugÃ¼n sana Ã§ok gÃ¼zel bir hikaye anlatacaÄŸÄ±m!",
                "Selam kÃ¼Ã§Ã¼k prenses! Hangi konuda hikaye istiyorsun?",
                "Merhaba canÄ±m! BugÃ¼n hangi masalÄ± dinlemek istersin?",
                "Selam prensesim! Sana Ã¶zel bir hikaye hazÄ±rladÄ±m!"
            ],
            
            'story_starters': [
                "Bir zamanlar, Ã§ok uzak diyarlarda...",
                "Masallar Ã¼lkesinde, gÃ¼zel bir prenses varmÄ±ÅŸ...",
                "Ã‡ok gÃ¼zel bir ormanda, sevimli hayvanlar yaÅŸarmÄ±ÅŸ...",
                "BÃ¼yÃ¼lÃ¼ bir krallÄ±kta, iyi kalpli bir peri varmÄ±ÅŸ...",
                "Uzak bir diyarda, cesur bir kÃ¼Ã§Ã¼k kÄ±z varmÄ±ÅŸ...",
                "Renkli Ã§iÃ§eklerle dolu bahÃ§ede, tatlÄ± bir hikaye baÅŸlar..."
            ],
            
            'story_endings': [
                "Ve iÅŸte hikayemiz bÃ¶yle bitiyor kÃ¼Ã§Ã¼k prenses!",
                "Hikayemiz burada son buluyor. Ã‡ok gÃ¼zeldi deÄŸil mi?",
                "Ve bÃ¶ylece mutlu mesut yaÅŸamÄ±ÅŸlar. Hikaye bÃ¶yle bitiyor prensesim!",
                "Ä°ÅŸte bu kadar gÃ¼zel hikayemiz! YarÄ±n yeni bir hikaye anlatÄ±rÄ±m sana!",
                "Ve bu gÃ¼zel hikayemiz bÃ¶yle sona eriyor. Seni Ã§ok seviyorum kÃ¼Ã§Ã¼k prenses!",
                "Ä°ÅŸte hikayemiz bÃ¶yle bitiyor. RÃ¼yalarÄ±nda da gÃ¼zel hikayeler gÃ¶receksin!"
            ],
            
            'moral_lessons': [
                "dostluÄŸun ne kadar Ã¶nemli olduÄŸunu",
                "paylaÅŸmanÄ±n gÃ¼zel olduÄŸunu",
                "iyiliÄŸin her zaman kazandÄ±ÄŸÄ±nÄ±",
                "sevginin her ÅŸeyi yendiÄŸini",
                "cesur olmanÄ±n Ã¶nemini",
                "baÅŸkalarÄ±na yardÄ±m etmenin gÃ¼zel olduÄŸunu",
                "sabÄ±rlÄ± olmanÄ±n deÄŸerini",
                "farklÄ±lÄ±klarÄ±n gÃ¼zel olduÄŸunu",
                "doÄŸruluk sÃ¶ylemenin Ã¶nemini"
            ],
            
            'theme_prompts': {
                'prenses': "GÃ¼zel bir prenses ve onun maceralarÄ± hakkÄ±nda",
                'peri': "BÃ¼yÃ¼lÃ¼ periler ve onlarÄ±n yaptÄ±ÄŸÄ± gÃ¼zel iÅŸler hakkÄ±nda",
                'dostluk': "GÃ¼zel dostluklar ve arkadaÅŸlÄ±k hakkÄ±nda",
                'macera': "Heyecan verici ama gÃ¼venli maceralar hakkÄ±nda",
                'hayvanlar': "Sevimli hayvanlar ve onlarÄ±n hikayeleri hakkÄ±nda",
                'doÄŸa': "GÃ¼zel doÄŸa, Ã§iÃ§ekler ve rengarenk bahÃ§eler hakkÄ±nda"
            }
        }
    
    async def initialize(self) -> bool:
        """Initialize the Turkish storyteller LLM service"""
        try:
            self.logger.info("Turkish StorytellerLLM servisi baÅŸlatÄ±lÄ±yor...")
            
            # Check if OpenAI is available
            if not openai or not OpenAI:
                self.logger.error("OpenAI kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil!")
                return False
            
            # Check API key
            if not self.openai_config['api_key'] or self.openai_config['api_key'] == 'YOUR_OPENAI_API_KEY':
                self.logger.error("OpenAI API anahtarÄ± bulunamadÄ±!")
                self.logger.error("LÃ¼tfen .env dosyasÄ±nda OPENAI_API_KEY deÄŸerini ayarlayÄ±n")
                return False
            
            # Initialize OpenAI client
            self.client = OpenAI(api_key=self.openai_config['api_key'])
            
            # Test connection
            await self._test_connection()
            
            self.is_initialized = True
            self.logger.info("âœ… Turkish StorytellerLLM servisi baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!")
            self.logger.info(f"ğŸ­ KonfigÃ¼rasyon: {self.child_config['name']}, {self.child_config['age']} yaÅŸ, {self.child_config['gender']}")
            self.logger.info(f"ğŸ“š Hikaye temalarÄ±: {', '.join(self.story_config['themes'])}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"Turkish StorytellerLLM baÅŸlatma hatasÄ±: {e}")
            return False
    
    async def _test_connection(self) -> bool:
        """Test OpenAI API connection"""
        try:
            # Simple test completion
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                    model=self.openai_config['model'],
                    messages=[
                        {"role": "system", "content": "Sen TÃ¼rkÃ§e hikaye anlatan bir asistansÄ±n."},
                        {"role": "user", "content": "Merhaba, test mesajÄ±"}
                    ],
                    max_tokens=50,
                    temperature=0.7
                )
            )
            
            self.logger.info("âœ… OpenAI API baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±!")
            return True
            
        except Exception as e:
            self.logger.error(f"OpenAI API baÄŸlantÄ± testi baÅŸarÄ±sÄ±z: {e}")
            raise
    
    def get_random_greeting(self) -> str:
        """Get a random Turkish greeting"""
        return random.choice(self.system_prompts['greeting_prompts'])
    
    def get_random_story_starter(self) -> str:
        """Get a random Turkish story starter"""
        return random.choice(self.system_prompts['story_starters'])
    
    def get_random_story_ending(self) -> str:
        """Get a random Turkish story ending"""
        return random.choice(self.system_prompts['story_endings'])
    
    def get_random_moral_lesson(self) -> str:
        """Get a random moral lesson"""
        return random.choice(self.system_prompts['moral_lessons'])
    
    def create_story_prompt(self, topic: Optional[str] = None, theme: Optional[str] = None) -> str:
        """Create a story prompt based on topic and theme"""
        starter = self.get_random_story_starter()
        ending = self.get_random_story_ending()
        moral = self.get_random_moral_lesson()
        
        # Select theme
        if not theme:
            theme = random.choice(self.story_config['themes'])
        
        theme_prompt = self.system_prompts['theme_prompts'].get(theme, "gÃ¼zel bir konu hakkÄ±nda")
        
        prompt = f"""
        GÃ–REV: {self.child_config['name']} isimli {self.child_config['age']} yaÅŸÄ±ndaki kÃ¼Ã§Ã¼k prenses iÃ§in bir hikaye anlat.
        
        Hikaye ÅŸÃ¶yle baÅŸlasÄ±n: "{starter}"
        
        Konu: {theme_prompt}
        {f"Ã–zel istek: {topic}" if topic else ""}
        
        Hikayenin sonunda {moral} Ã¶ÄŸretmelisin.
        
        Hikayen tam olarak 150-200 kelime olmalÄ± ve "{ending}" ÅŸeklinde bitmelisin.
        
        Ã–NEMLÄ° KURALLAR:
        - Sadece TÃ¼rkÃ§e konuÅŸ
        - 5 yaÅŸÄ±na uygun kelimeler kullan
        - KÄ±sa ve anlaÅŸÄ±lÄ±r cÃ¼mleler kur
        - KorkunÃ§, Ã¼zÃ¼cÃ¼ ÅŸeyler anlatma
        - Hikayeyi eÄŸlenceli ve sevecen anlat
        - GÃ¼zel bir mesaj ver
        """
        
        return prompt
    
    async def generate_story(self, topic: Optional[str] = None, theme: Optional[str] = None) -> Dict[str, Any]:
        """Generate a Turkish story for the child"""
        if not self.is_initialized:
            raise RuntimeError("Turkish StorytellerLLM servisi baÅŸlatÄ±lmamÄ±ÅŸ!")
        
        try:
            self.logger.info(f"Hikaye Ã¼retiliyor... Konu: {topic}, Tema: {theme}")
            
            # Create story prompt
            story_prompt = self.create_story_prompt(topic, theme)
            
            # Generate story using OpenAI
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                    model=self.openai_config['model'],
                    messages=[
                        {"role": "system", "content": self.system_prompts['main_system_prompt']},
                        {"role": "user", "content": story_prompt}
                    ],
                    max_tokens=self.openai_config['max_tokens'],
                    temperature=self.openai_config['temperature'],
                    top_p=self.openai_config['top_p'],
                    frequency_penalty=self.openai_config['frequency_penalty'],
                    presence_penalty=self.openai_config['presence_penalty']
                )
            )
            
            story_text = response.choices[0].message.content.strip()
            
            # Create story metadata
            story_data = {
                'text': story_text,
                'topic': topic,
                'theme': theme or random.choice(self.story_config['themes']),
                'child_name': self.child_config['name'],
                'timestamp': datetime.now().isoformat(),
                'language': 'turkish',
                'target_audience': self.child_config['target_audience'],
                'word_count': len(story_text.split()),
                'estimated_duration': len(story_text.split()) * 0.6,  # ~0.6 seconds per word in Turkish
                'model_used': self.openai_config['model'],
                'content_filter_level': self.story_config['content_filter']
            }
            
            # Add to history
            self.story_history.append(story_data)
            
            # Keep only last 10 stories
            if len(self.story_history) > 10:
                self.story_history = self.story_history[-10:]
            
            self.logger.info(f"âœ… Hikaye baÅŸarÄ±yla Ã¼retildi! Kelime sayÄ±sÄ±: {story_data['word_count']}")
            self.logger.info(f"ğŸ“– Tahmini sÃ¼re: {story_data['estimated_duration']:.1f} saniye")
            
            return story_data
            
        except Exception as e:
            self.logger.error(f"Hikaye Ã¼retme hatasÄ±: {e}")
            raise
    
    async def generate_greeting(self) -> str:
        """Generate a personalized Turkish greeting"""
        try:
            greeting_prompt = f"""
            {self.child_config['name']} isimli {self.child_config['age']} yaÅŸÄ±ndaki kÃ¼Ã§Ã¼k prenses iÃ§in 
            sÄ±cak ve sevecen bir karÅŸÄ±lama sÃ¶zÃ¼ sÃ¶yle. Ona hikaye anlatacaÄŸÄ±nÄ± ve ne tÃ¼r hikaye 
            istediÄŸini sor. Ã‡ok kÄ±sa (1-2 cÃ¼mle) olsun.
            """
            
            if not self.is_initialized:
                # Fallback to predefined greetings
                return self.get_random_greeting()
            
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                    model=self.openai_config['model'],
                    messages=[
                        {"role": "system", "content": self.system_prompts['main_system_prompt']},
                        {"role": "user", "content": greeting_prompt}
                    ],
                    max_tokens=100,
                    temperature=0.8
                )
            )
            
            greeting = response.choices[0].message.content.strip()
            self.logger.info(f"KiÅŸiselleÅŸtirilmiÅŸ karÅŸÄ±lama Ã¼retildi: {greeting[:50]}...")
            
            return greeting
            
        except Exception as e:
            self.logger.error(f"KarÅŸÄ±lama Ã¼retme hatasÄ±: {e}")
            # Return random greeting as fallback
            return self.get_random_greeting()
    
    async def continue_story(self, story_context: str, user_input: str) -> str:
        """Continue an existing story based on user input"""
        try:
            continue_prompt = f"""
            Bu hikayenin devamÄ±nÄ± getir:
            
            Ã–nceki hikaye: {story_context}
            
            Ã‡ocuÄŸun isteÄŸi: {user_input}
            
            Hikayeyi 2-3 cÃ¼mle ile devam ettir. Hikayeyi gÃ¼zel bir ÅŸekilde bitir.
            """
            
            if not self.is_initialized:
                return "Hikaye devam ettirilemiyor. Servis hazÄ±r deÄŸil."
            
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                    model=self.openai_config['model'],
                    messages=[
                        {"role": "system", "content": self.system_prompts['main_system_prompt']},
                        {"role": "user", "content": continue_prompt}
                    ],
                    max_tokens=200,
                    temperature=0.8
                )
            )
            
            continuation = response.choices[0].message.content.strip()
            self.logger.info("Hikaye devamÄ± Ã¼retildi")
            
            return continuation
            
        except Exception as e:
            self.logger.error(f"Hikaye devamÄ± hatasÄ±: {e}")
            return "ÃœzgÃ¼nÃ¼m, hikayeyi devam ettiremiyorum. Yeni bir hikaye anlatayÄ±m mÄ±?"
    
    def get_story_history(self) -> List[Dict[str, Any]]:
        """Get the story history"""
        return self.story_history.copy()
    
    def get_last_story(self) -> Optional[Dict[str, Any]]:
        """Get the last generated story"""
        return self.story_history[-1] if self.story_history else None
    
    def get_available_themes(self) -> List[str]:
        """Get available story themes"""
        return self.story_config['themes'].copy()
    
    def get_service_status(self) -> Dict[str, Any]:
        """Get service status"""
        return {
            'initialized': self.is_initialized,
            'service_name': 'Turkish StorytellerLLM',
            'child_config': self.child_config,
            'story_config': self.story_config,
            'stories_generated': len(self.story_history),
            'last_story_time': self.story_history[-1]['timestamp'] if self.story_history else None,
            'available_themes': self.get_available_themes(),
            'api_model': self.openai_config['model'],
            'processing_mode': 'remote_only'
        }
    
    async def cleanup(self) -> None:
        """Clean up resources"""
        try:
            if self.client:
                # OpenAI client doesn't need explicit cleanup
                pass
            
            self.is_initialized = False
            self.logger.info("Turkish StorytellerLLM servisi temizlendi")
            
        except Exception as e:
            self.logger.error(f"Temizlik hatasÄ±: {e}")

# Test function
async def test_turkish_storyteller():
    """Test the Turkish storyteller service"""
    print("ğŸ­ Turkish StorytellerLLM Test BaÅŸlÄ±yor...")
    
    # Initialize service
    storyteller = TurkishStorytellerLLM()
    
    try:
        # Test initialization
        print("ğŸ“š Servis baÅŸlatÄ±lÄ±yor...")
        success = await storyteller.initialize()
        
        if not success:
            print("âŒ Servis baÅŸlatÄ±lamadÄ±!")
            return False
        
        print("âœ… Servis baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!")
        
        # Test greeting
        print("\nğŸ‘‹ KarÅŸÄ±lama testi...")
        greeting = await storyteller.generate_greeting()
        print(f"KarÅŸÄ±lama: {greeting}")
        
        # Test story generation
        print("\nğŸ“– Hikaye Ã¼retim testi...")
        story = await storyteller.generate_story(theme='prenses')
        print(f"Hikaye: {story['text'][:100]}...")
        print(f"Kelime sayÄ±sÄ±: {story['word_count']}")
        print(f"Tahmini sÃ¼re: {story['estimated_duration']:.1f} saniye")
        
        # Test service status
        print("\nğŸ“Š Servis durumu:")
        status = storyteller.get_service_status()
        for key, value in status.items():
            print(f"  {key}: {value}")
        
        print("\nâœ… TÃ¼m testler baÅŸarÄ±lÄ±!")
        return True
        
    except Exception as e:
        print(f"âŒ Test hatasÄ±: {e}")
        return False
    
    finally:
        await storyteller.cleanup()

if __name__ == '__main__':
    asyncio.run(test_turkish_storyteller())